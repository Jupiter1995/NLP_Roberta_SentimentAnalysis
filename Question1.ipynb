{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IJcgMmjf6jsN"
   },
   "source": [
    "## 1 Fine-Tunning Section\n",
    "Due to the limitation of computing resources and the time constrain, Initially, I tried to use partial dataset to fine-tune the model. In reality, cloud computing resources or a laptop with GPU should be used to accelerate the training process. <br>\n",
    "When actually starting training the model, it took too long to even barely finish training epoches when reaching to the end of the exam time. However, there was no error countered during the compiling and while running the preparation data codes. Therefore, the codes should all work but just need more time to train and get the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38914,
     "status": "ok",
     "timestamp": 1683652733661,
     "user": {
      "displayName": "Linhan Yang",
      "userId": "16264260579274210300"
     },
     "user_tz": 240
    },
    "id": "35wlylSApo4P",
    "outputId": "0afb63d7-3e61-4f34-b335-aaf6d641e28e"
   },
   "outputs": [],
   "source": [
    "# import libararies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "# from GPUtil import showUtilization as gpu_usage\n",
    "# !pip install numba\n",
    "# from numba import cuda\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# !pip install transformers\n",
    "from transformers import RobertaTokenizer, RobertaModel, Pipeline\n",
    "from transformers.pipelines import PIPELINE_REGISTRY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1994,
     "status": "ok",
     "timestamp": 1683652794339,
     "user": {
      "displayName": "Linhan Yang",
      "userId": "16264260579274210300"
     },
     "user_tz": 240
    },
    "id": "FKagm5O2po4R",
    "outputId": "46d5fb9f-ad0e-482f-e5c9-d32519d84148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyarrow._parquet.ParquetSchema object at 0x000001EEB01770C0>\n",
      "required group field_id=-1 schema {\n",
      "  optional binary field_id=-1 sentence (String);\n",
      "  optional int64 field_id=-1 label;\n",
      "}\n",
      "\n",
      "                                            sentence  label\n",
      "0  Altia 's operating profit jumped to EUR 47 mil...      2\n",
      "1  The agreement was signed with Biohit Healthcar...      2\n",
      "2  Kesko pursues a strategy of healthy , focused ...      2\n",
      "3  Vaisala , headquartered in Helsinki in Finland...      1\n",
      "4  Also , a six-year historic analysis is provide...      1\n",
      "                                            sentence  label\n",
      "0  TeliaSonera TLSN said the offer is in line wit...      2\n",
      "1  STORA ENSO , NORSKE SKOG , M-REAL , UPM-KYMMEN...      2\n",
      "2  Clothing retail chain Sepp+ñl+ñ 's sales incre...      2\n",
      "3  Lifetree was founded in 2000 , and its revenue...      2\n",
      "4  Nordea Group 's operating profit increased in ...      2\n"
     ]
    }
   ],
   "source": [
    "# Open dataset for test and train\n",
    "\n",
    "# Open the Parquet file\n",
    "train_file = pq.ParquetFile('./train-sentiment.parquet')\n",
    "test_file = pq.ParquetFile('./test-sentiment.parquet')\n",
    "\n",
    "# Get the schema of the file\n",
    "schema = train_file.schema\n",
    "\n",
    "# Read the data into a Pandas DataFrame\n",
    "train_raw = train_file.read().to_pandas()\n",
    "test = test_file.read().to_pandas()\n",
    "\n",
    "# Print the schema and data\n",
    "print(schema)\n",
    "print(train_raw.head())\n",
    "print(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "a06c36583a5f4ac2b885b81c8fea482d",
      "3aa0ccec5d8a47be8047a47648922fa8",
      "8fa639a2dcfc47969cac0cbe0a12071f",
      "1476d053dee94e358a87e27182a8e124",
      "219d50a43f504fef9079c717fc90f0d2",
      "31e1b38261384e40a6e6254b97edd569",
      "8ec44f4f35a444b2ae139b7e9f691eb3",
      "78368beff40c4195ac91be8b06ff4bf2",
      "0701ad49fb994d17a59dae220cbe1d87",
      "5f1f0e1c5e654ad0ac08c9e2e87cef46",
      "6416dace168241448a46515a2df2ce85",
      "e1f8679b7c2747b18337947e138e3302",
      "baf89fc92bfc431088a5ad39ea9c7fc0",
      "4c3c12ec3de44174911b0bb5ee5e8457",
      "06249ebfecef4be1bb288bcca60edd3c",
      "7a3cb79e4db047009c9c0937315c5b79",
      "d09405610c6149e6a9528fb013f1977c",
      "21160254ee7848b9841b06e5886f9c36",
      "72e07fad05904b019669b46489bcc76f",
      "b29bf428e8184fd383b9a56f971ac107",
      "0ce82819f04e4215bef1aae4db707b24",
      "258473bd530b460891c6dc23582c44b5",
      "78625ed8629b42b587cfeda4d41a589d",
      "f0263a48a0814f2f955b121dfdc77b60",
      "7db7a3a3488a44a2b63280621c79cc5d",
      "bb7aab35536d4d3dadf2fbed9fb4e62b",
      "6e0bca4f144645eeb1e409dff98eaa7f",
      "08d8eb76c69d466995092425bd922397",
      "dc7a4f7a434949f597d0f14a26a4f355",
      "3041e87694bf4d85a415239690904a03",
      "caf8549bbde642659060f4eb79e39efc",
      "3ee4e165661e432da46e97dec0d611e4",
      "d4c30142de0d40ff82b166a4e913a322"
     ]
    },
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1683652798090,
     "user": {
      "displayName": "Linhan Yang",
      "userId": "16264260579274210300"
     },
     "user_tz": 240
    },
    "id": "kKd8ulbNpo4S",
    "outputId": "5d9700ac-982d-447f-f1a0-942fa3dd9606"
   },
   "outputs": [],
   "source": [
    "# Generate dataset for fine-tunning\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = list(df['label'].values)\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['sentence']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 139,
     "status": "ok",
     "timestamp": 1683652799479,
     "user": {
      "displayName": "Linhan Yang",
      "userId": "16264260579274210300"
     },
     "user_tz": 240
    },
    "id": "4CZqECRvsUm-",
    "outputId": "200d9565-e785-4326-b800-818f3b31331d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3102, 2)\n",
      "Testing set shape: (775, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split raw train dataset into train and validation datasets\n",
    "np.random.seed(112)\n",
    "\n",
    "# Define the proportion of data to use for validating\n",
    "val_size = 0.2\n",
    "\n",
    "# Calculate the number of samples to use for testing\n",
    "num_val_samples = int(len(train_raw) * val_size)\n",
    "\n",
    "# Generate a random permutation of the data indices\n",
    "indices = np.random.permutation(len(train_raw))\n",
    "\n",
    "# Split the indices into training and testing indices\n",
    "val_indices = indices[:num_val_samples]\n",
    "train_indices = indices[num_val_samples:]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = train_raw.iloc[train_indices]\n",
    "val_data = train_raw.iloc[val_indices]\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print('Training set shape:', train_data.shape)\n",
    "print('Testing set shape:', val_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NY1hhn0ubEVu"
   },
   "source": [
    "### 1.1 Freeze all the layers expect of classifier and tune head only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1683652801518,
     "user": {
      "displayName": "Linhan Yang",
      "userId": "16264260579274210300"
     },
     "user_tz": 240
    },
    "id": "HvPmHagzuIE_"
   },
   "outputs": [],
   "source": [
    "# Construct the classifier for sentiment analysis\n",
    "class SentimentCalssify(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(SentimentCalssify, self).__init__()\n",
    "\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "        # Freeze all layers except the classifier (the last layer)\n",
    "        for name, param in self.roberta.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        self.l1 = nn.Linear(768, 768)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.roberta(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        pre_classify = self.l1(pooled_output)\n",
    "        dropout_output = self.dropout(pre_classify)\n",
    "        activate_output = self.activation(dropout_output)\n",
    "        linear_output = self.linear(activate_output)\n",
    "\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4375221,
     "status": "ok",
     "timestamp": 1683661494659,
     "user": {
      "displayName": "Linhan Yang",
      "userId": "16264260579274210300"
     },
     "user_tz": 240
    },
    "id": "jwzsw-7fu91-",
    "outputId": "fc28ed5b-7d09-4ef0-9df1-d86d34553d8e"
   },
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=8, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=8)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        torch.cuda.empty_cache()\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    non_frozen_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    print(f\"tunable parameters: {[n for n, p in model.named_parameters() if p.requires_grad]}\")\n",
    "    optimizer = Adam(non_frozen_params, lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "            # for train_input, train_label in train_dataloader:\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "                model.zero_grad()\n",
    "                \n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunable parameters: ['l1.weight', 'l1.bias', 'linear.weight', 'linear.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [01:41<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.097                 | Train Accuracy:  0.569                 | Val Loss:  0.094                 | Val Accuracy:  0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [01:41<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.092                 | Train Accuracy:  0.601                 | Val Loss:  0.095                 | Val Accuracy:  0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [01:42<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.092                 | Train Accuracy:  0.601                 | Val Loss:  0.094                 | Val Accuracy:  0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [01:43<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.092                 | Train Accuracy:  0.601                 | Val Loss:  0.094                 | Val Accuracy:  0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [01:44<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.092                 | Train Accuracy:  0.601                 | Val Loss:  0.094                 | Val Accuracy:  0.588\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = SentimentCalssify(dropout=0.3)\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, train_data, val_data, LR, EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "H4BUn8U5bSPC"
   },
   "source": [
    "### 1.2 Unfreeze last 3 layers of the model and tune them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 128,
     "status": "error",
     "timestamp": 1683662382754,
     "user": {
      "displayName": "Linhan Yang",
      "userId": "16264260579274210300"
     },
     "user_tz": 240
    },
    "id": "SLslJVX79LLP",
    "outputId": "5adc4857-89ef-4a8e-dc21-86f246d21dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunable parameters: ['roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'l1.weight', 'l1.bias', 'linear.weight', 'linear.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388/388 [03:28<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.074                 | Train Accuracy:  0.753                 | Val Loss:  0.045                 | Val Accuracy:  0.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388/388 [03:31<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.038                 | Train Accuracy:  0.874                 | Val Loss:  0.042                 | Val Accuracy:  0.863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388/388 [03:35<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.027                 | Train Accuracy:  0.915                 | Val Loss:  0.046                 | Val Accuracy:  0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388/388 [03:35<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.019                 | Train Accuracy:  0.943                 | Val Loss:  0.051                 | Val Accuracy:  0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388/388 [03:32<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.011                 | Train Accuracy:  0.971                 | Val Loss:  0.056                 | Val Accuracy:  0.854\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the last 3 layers and retrain the model\n",
    "EPOCHS = 5\n",
    "LR = 1e-5\n",
    "\n",
    "for name, param in model.roberta.named_parameters():\n",
    "  temp = name.split('.')\n",
    "  if temp[2].isdigit() and int(temp[2]) >= 9 or temp[0] == \"pooler\" : \n",
    "    param.requires_grad = True\n",
    "              \n",
    "train(model, train_data, val_data, LR, EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TsPhoFlObXM8"
   },
   "source": [
    "### 1.3 Evaluate finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "TLDefs8q9-5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.867\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=10)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "\n",
    "idx = int(0.8 * test.shape[0])\n",
    "evaluate(model, test.iloc[:idx, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "U-_AUWThbdpv"
   },
   "source": [
    "### 1.4 Use Pipelines to create prediction pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "7aIkbGXuaQGP"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unknown task sentiment-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\SESA679501\\Documents\\workspace\\NLP_exam_Raymond\\Question1.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SESA679501/Documents/workspace/NLP_exam_Raymond/Question1.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a new pipeline for re-trained RoBerta model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/SESA679501/Documents/workspace/NLP_exam_Raymond/Question1.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sentimentCalssify \u001b[39m=\u001b[39m pipeline(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SESA679501/Documents/workspace/NLP_exam_Raymond/Question1.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39msentiment-classification\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SESA679501/Documents/workspace/NLP_exam_Raymond/Question1.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SESA679501/Documents/workspace/NLP_exam_Raymond/Question1.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SESA679501/Documents/workspace/NLP_exam_Raymond/Question1.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SESA679501/Documents/workspace/NLP_exam_Raymond/Question1.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Using example - Inference stage\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SESA679501/Documents/workspace/NLP_exam_Raymond/Question1.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pipe \u001b[39m=\u001b[39m pipeline(\u001b[39m'\u001b[39m\u001b[39msentiment-classification\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\SESA679501\\Miniconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py:744\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    740\u001b[0m         pipeline_class \u001b[39m=\u001b[39m get_class_from_dynamic_module(\n\u001b[0;32m    741\u001b[0m             class_ref, model, revision\u001b[39m=\u001b[39mrevision, use_auth_token\u001b[39m=\u001b[39muse_auth_token\n\u001b[0;32m    742\u001b[0m         )\n\u001b[0;32m    743\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     normalized_task, targeted_task, task_options \u001b[39m=\u001b[39m check_task(task)\n\u001b[0;32m    745\u001b[0m     \u001b[39mif\u001b[39;00m pipeline_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    746\u001b[0m         pipeline_class \u001b[39m=\u001b[39m targeted_task[\u001b[39m\"\u001b[39m\u001b[39mimpl\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\SESA679501\\Miniconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py:487\u001b[0m, in \u001b[0;36mcheck_task\u001b[1;34m(task)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_task\u001b[39m(task: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mstr\u001b[39m, Dict, Any]:\n\u001b[0;32m    446\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m    Checks an incoming task string, to validate it's correct and return the default Pipeline and Model classes, and\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[39m    default models if they exist.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m     \u001b[39mreturn\u001b[39;00m PIPELINE_REGISTRY\u001b[39m.\u001b[39;49mcheck_task(task)\n",
      "File \u001b[1;32mc:\\Users\\SESA679501\\Miniconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1194\u001b[0m, in \u001b[0;36mPipelineRegistry.check_task\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[39mreturn\u001b[39;00m task, targeted_task, (tokens[\u001b[39m1\u001b[39m], tokens[\u001b[39m3\u001b[39m])\n\u001b[0;32m   1192\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid translation task \u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m}\u001b[39;00m\u001b[39m, use \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtranslation_XX_to_YY\u001b[39m\u001b[39m'\u001b[39m\u001b[39m format\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1194\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m   1195\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown task \u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m}\u001b[39;00m\u001b[39m, available tasks are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_supported_tasks() \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mtranslation_XX_to_YY\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1196\u001b[0m )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unknown task sentiment-classification, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']\""
     ]
    }
   ],
   "source": [
    "# Create a new pipeline for re-trained RoBerta model\n",
    "from transformers import Pipeline\n",
    "\n",
    "\n",
    "class MyPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"maybe_arg\" in kwargs:\n",
    "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, inputs, maybe_arg=2):\n",
    "        model_input = Tensor(inputs[\"input_ids\"])\n",
    "        return {\"model_input\": model_input}\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        # model_inputs == {\"model_input\": model_input}\n",
    "        outputs = self.model(**model_inputs)\n",
    "        # Maybe {\"logits\": Tensor(...)}\n",
    "        return outputs\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        best_class = model_outputs[\"logits\"].softmax(-1)\n",
    "        return best_class"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06249ebfecef4be1bb288bcca60edd3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ce82819f04e4215bef1aae4db707b24",
      "placeholder": "​",
      "style": "IPY_MODEL_258473bd530b460891c6dc23582c44b5",
      "value": " 456k/456k [00:00&lt;00:00, 24.6MB/s]"
     }
    },
    "0701ad49fb994d17a59dae220cbe1d87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "08d8eb76c69d466995092425bd922397": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ce82819f04e4215bef1aae4db707b24": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1476d053dee94e358a87e27182a8e124": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f1f0e1c5e654ad0ac08c9e2e87cef46",
      "placeholder": "​",
      "style": "IPY_MODEL_6416dace168241448a46515a2df2ce85",
      "value": " 899k/899k [00:00&lt;00:00, 27.1MB/s]"
     }
    },
    "21160254ee7848b9841b06e5886f9c36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "219d50a43f504fef9079c717fc90f0d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "258473bd530b460891c6dc23582c44b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3041e87694bf4d85a415239690904a03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31e1b38261384e40a6e6254b97edd569": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aa0ccec5d8a47be8047a47648922fa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31e1b38261384e40a6e6254b97edd569",
      "placeholder": "​",
      "style": "IPY_MODEL_8ec44f4f35a444b2ae139b7e9f691eb3",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "3ee4e165661e432da46e97dec0d611e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c3c12ec3de44174911b0bb5ee5e8457": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72e07fad05904b019669b46489bcc76f",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b29bf428e8184fd383b9a56f971ac107",
      "value": 456318
     }
    },
    "5f1f0e1c5e654ad0ac08c9e2e87cef46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6416dace168241448a46515a2df2ce85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e0bca4f144645eeb1e409dff98eaa7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72e07fad05904b019669b46489bcc76f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78368beff40c4195ac91be8b06ff4bf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78625ed8629b42b587cfeda4d41a589d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f0263a48a0814f2f955b121dfdc77b60",
       "IPY_MODEL_7db7a3a3488a44a2b63280621c79cc5d",
       "IPY_MODEL_bb7aab35536d4d3dadf2fbed9fb4e62b"
      ],
      "layout": "IPY_MODEL_6e0bca4f144645eeb1e409dff98eaa7f"
     }
    },
    "7a3cb79e4db047009c9c0937315c5b79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7db7a3a3488a44a2b63280621c79cc5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3041e87694bf4d85a415239690904a03",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_caf8549bbde642659060f4eb79e39efc",
      "value": 481
     }
    },
    "8ec44f4f35a444b2ae139b7e9f691eb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8fa639a2dcfc47969cac0cbe0a12071f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78368beff40c4195ac91be8b06ff4bf2",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0701ad49fb994d17a59dae220cbe1d87",
      "value": 898823
     }
    },
    "a06c36583a5f4ac2b885b81c8fea482d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3aa0ccec5d8a47be8047a47648922fa8",
       "IPY_MODEL_8fa639a2dcfc47969cac0cbe0a12071f",
       "IPY_MODEL_1476d053dee94e358a87e27182a8e124"
      ],
      "layout": "IPY_MODEL_219d50a43f504fef9079c717fc90f0d2"
     }
    },
    "b29bf428e8184fd383b9a56f971ac107": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "baf89fc92bfc431088a5ad39ea9c7fc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d09405610c6149e6a9528fb013f1977c",
      "placeholder": "​",
      "style": "IPY_MODEL_21160254ee7848b9841b06e5886f9c36",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "bb7aab35536d4d3dadf2fbed9fb4e62b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ee4e165661e432da46e97dec0d611e4",
      "placeholder": "​",
      "style": "IPY_MODEL_d4c30142de0d40ff82b166a4e913a322",
      "value": " 481/481 [00:00&lt;00:00, 22.5kB/s]"
     }
    },
    "caf8549bbde642659060f4eb79e39efc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d09405610c6149e6a9528fb013f1977c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4c30142de0d40ff82b166a4e913a322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc7a4f7a434949f597d0f14a26a4f355": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1f8679b7c2747b18337947e138e3302": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_baf89fc92bfc431088a5ad39ea9c7fc0",
       "IPY_MODEL_4c3c12ec3de44174911b0bb5ee5e8457",
       "IPY_MODEL_06249ebfecef4be1bb288bcca60edd3c"
      ],
      "layout": "IPY_MODEL_7a3cb79e4db047009c9c0937315c5b79"
     }
    },
    "f0263a48a0814f2f955b121dfdc77b60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08d8eb76c69d466995092425bd922397",
      "placeholder": "​",
      "style": "IPY_MODEL_dc7a4f7a434949f597d0f14a26a4f355",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
